# live_client_test.py
# - ì¹´ë©”ë¼ë¡œë¶€í„° í”„ë ˆì„ -> MediaPipeë¡œ keypoints ì¶”ì¶œ -> REST(POST /predict/frame)ë¡œ ì „ì†¡
# - ì„œë²„ ì‘ë‹µ(label, confidence)ì„ ë°›ì•„ì„œ í™”ë©´ì— í•œê¸€ë¡œ í‘œì‹œ + ë¬¸ì¥ ëˆ„ì  ë¡œì§

import cv2
import mediapipe as mp
import numpy as np
import json
import time
import uuid
import requests
from PIL import ImageFont, ImageDraw, Image  # í•œê¸€ ì¶œë ¥ìš©

# ====================== ì„¤ì • ======================
API_URL = "http://localhost:8000/predict/frame"  # ë„ì»¤ API ì—”ë“œí¬ì¸íŠ¸
SESSION_ID = str(uuid.uuid4())                   # ì„¸ì…˜ ê³ ìœ  ID (ê¸°ê¸°/ë¸Œë¼ìš°ì €ë³„ë¡œ ê³ ì • ê¶Œì¥)
TIMEOUT = 3                                      # ìš”ì²­ íƒ€ì„ì•„ì›ƒ(ì´ˆ)

# ëª¨ë¸/ì „ì²˜ë¦¬ ìŠ¤í™(ì„œë²„ì™€ ë°˜ë“œì‹œ ë™ì¼)
POSE_SKIP_INDEXES = set(range(17, 33))  # í•˜ì²´ ì œì™¸
EXPECTED_KEYPOINTS = 194
WINDOW = 10                   # ì„œë²„ WINDOWì™€ ë™ì¼
CONFIDENCE_THRESHOLD = 0.4    # ì„œë²„ CONF_THRESHOLDì™€ ë™ì¼(ì„œë²„ë„ ìµœì¢…ì ìš©í•¨)
MAX_PADDING_RATIO = 0.5       # ìœ íš¨ì„± í•„í„°(í´ë¼ ì¸¡)
RESET_INTERVAL = 5.0          # ë¬¸ì¥ ì´ˆê¸°í™” ê°„ê²©(ì´ˆ)
STABLE_THRESHOLD = 3          # ê°™ì€ ë¼ë²¨ ì—°ì† ê°ì§€ ì‹œ ë¬¸ì¥ ëˆ„ì 
MIN_INTERVAL_BETWEEN_SAME_WORD = 1.0  # ê°™ì€ ë‹¨ì–´ ì—°ì† ë°©ì§€ ê°„ê²©(ì´ˆ)

# ================== í•œê¸€ í…ìŠ¤íŠ¸ ì¶œë ¥ =================
def draw_text_korean(frame, text, position, font_size=30, color=(255,255,255)):
    # Windows í°íŠ¸ ê²½ë¡œ
    font_path = "C:/Windows/Fonts/malgun.ttf"
    font = ImageFont.truetype(font_path, font_size)
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ================== MediaPipe ì´ˆê¸°í™” =================
mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils
holistic = mp_holistic.Holistic(min_detection_confidence=0.7, min_tracking_confidence=0.7)

# ================== ìƒíƒœ ë³€ìˆ˜ ======================
last_label = None
stable_count = 0
output_sentence = []
last_add_time = time.time()

cap = cv2.VideoCapture(0)

def extract_landmarks(landmarks, dims=3, skip=None):
    result = []
    if landmarks:
        for i, lm in enumerate(landmarks.landmark):
            if skip and i in skip:
                continue
            coords = [lm.x, lm.y, lm.z]
            if dims == 4:
                coords.append(getattr(lm, 'visibility', 0.0))
            result.extend(coords)
    return result

print("ğŸ” ì‹¤ì‹œê°„ ìˆ˜ì–´ ì˜ˆì¸¡ (REST ê°œë³„ ì „ì†¡ / që¡œ ì¢…ë£Œ)")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        continue

    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = holistic.process(image_rgb)
    display_frame = frame.copy()

    # ì–‘ì† ëª¨ë‘ ì—†ìœ¼ë©´ skip
    if results.left_hand_landmarks is None and results.right_hand_landmarks is None:
        stable_count = 0
        last_label = None
        label_text = "ì—†ìŒ"
        confidence = 0.0
        display_frame = draw_text_korean(display_frame, f"{label_text} ({confidence:.2f})", (10, 30), 32, (0, 0, 255))
        display_frame = draw_text_korean(display_frame, ' '.join(output_sentence), (10, 70), 28, (255,255,255))
        cv2.imshow("ì‹¤ì‹œê°„ ìˆ˜ì–´ ì˜ˆì¸¡(REST)", display_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    # ëœë“œë§ˆí¬ ì¶”ì¶œ (ì¢Œ/ìš°ì† + ìƒì²´ í¬ì¦ˆ)
    lh = extract_landmarks(results.left_hand_landmarks, dims=3)
    rh = extract_landmarks(results.right_hand_landmarks, dims=3)
    pose = extract_landmarks(results.pose_landmarks, dims=4, skip=POSE_SKIP_INDEXES)
    keypoints = lh + rh + pose

    # 0íŒ¨ë”©/ìë¥´ê¸°
    if len(keypoints) < EXPECTED_KEYPOINTS:
        keypoints += [0.0] * (EXPECTED_KEYPOINTS - len(keypoints))
    elif len(keypoints) > EXPECTED_KEYPOINTS:
        keypoints = keypoints[:EXPECTED_KEYPOINTS]

    # ìœ íš¨ì„± í•„í„°(í´ë¼ì´ì–¸íŠ¸ ì¸¡)
    zero_ratio = keypoints.count(0.0) / EXPECTED_KEYPOINTS
    if zero_ratio > MAX_PADDING_RATIO:
        stable_count = 0
        last_label = None
        label_text = "ë¬´íš¨"
        confidence = 0.0
        display_frame = draw_text_korean(display_frame, f"{label_text} ({confidence:.2f})", (10, 30), 32, (0, 0, 255))
        display_frame = draw_text_korean(display_frame, ' '.join(output_sentence), (10, 70), 28, (255,255,255))
        cv2.imshow("ì‹¤ì‹œê°„ ìˆ˜ì–´ ì˜ˆì¸¡(REST)", display_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    # ====== ì„œë²„ë¡œ í”„ë ˆì„ 1ê°œ ì „ì†¡ (REST) ======
    try:
        payload = {
            "session_id": SESSION_ID,
            "keypoints": keypoints  # ì„œë²„ëŠ” ê¸¸ì´ 194 ë²¡í„° 1ê°œë¥¼ ë°›ìŒ
        }
        r = requests.post(API_URL, json=payload, timeout=TIMEOUT)
        if r.status_code != 200:
            # ì„œë²„ê°€ 4xx/5xxë¥¼ ë˜ì§€ë©´ ë¡œê·¸ë§Œ ì°ê³  ë‹¤ìŒ í”„ë ˆì„ ì§„í–‰
            print(f"[HTTP {r.status_code}] {r.text}")
            label_text = "ì—ëŸ¬"
            confidence = 0.0
        else:
            resp = r.json()
            # ìˆ˜ì§‘ ì¤‘ ìƒíƒœ
            if resp.get("status") == "collecting":
                collected = resp.get("collected", 0)
                label_text = f"ìˆ˜ì§‘ì¤‘ {collected}/{WINDOW}"
                confidence = 0.0
            else:
                # ì˜ˆì¸¡ ì™„ë£Œ ì‘ë‹µ
                predicted_label = resp.get("label", "None")
                confidence = float(resp.get("confidence", 0.0))
                label_text = "ì—†ìŒ" if predicted_label in ["None", "none"] else predicted_label

                # ë¬¸ì¥ ëˆ„ì  (í´ë¼ ì¸¡ ì•ˆì •í™” ë¡œì§)
                if predicted_label not in ["None", "none"]:
                    if predicted_label == last_label:
                        stable_count += 1
                    else:
                        last_label = predicted_label
                        stable_count = 1

                    if stable_count == STABLE_THRESHOLD:
                        if not output_sentence or predicted_label != output_sentence[-1]:
                            if time.time() - last_add_time > MIN_INTERVAL_BETWEEN_SAME_WORD:
                                output_sentence.append(predicted_label)
                                last_add_time = time.time()
                                if len(output_sentence) > 10:
                                    output_sentence = output_sentence[-10:]
                else:
                    stable_count = 0
                    last_label = None

    except requests.exceptions.RequestException as e:
        print(f"[REQUEST ERROR] {e}")
        label_text = "ë„¤íŠ¸ì›Œí¬ì˜¤ë¥˜"
        confidence = 0.0

    # ë¬¸ì¥ ì´ˆê¸°í™” íƒ€ì´ë¨¸
    if output_sentence and (time.time() - last_add_time > RESET_INTERVAL):
        output_sentence = []

    # ====== ì‹œê°í™” ======
    display_frame = draw_text_korean(
        display_frame,
        f'{label_text} ({confidence:.2f})',
        (10, 30),
        font_size=32,
        color=(0,255,0) if label_text not in ["ì—†ìŒ", "ë¬´íš¨", "ì—ëŸ¬", "ë„¤íŠ¸ì›Œí¬ì˜¤ë¥˜"] else (0,0,255)
    )
    display_frame = draw_text_korean(display_frame, ' '.join(output_sentence), (10, 70), 28, (255,255,255))

    # ëœë“œë§ˆí¬ ì‹œê°í™”(ë””ë²„ê¹…ìš©)
    mp_drawing.draw_landmarks(display_frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)
    mp_drawing.draw_landmarks(display_frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)
    mp_drawing.draw_landmarks(display_frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)

    cv2.imshow("ì‹¤ì‹œê°„ ìˆ˜ì–´ ì˜ˆì¸¡(REST)", display_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()